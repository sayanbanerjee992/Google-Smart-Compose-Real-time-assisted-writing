{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gmail Smart Compose: Real-Time Assisted Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Kw6CWKSIBBq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import email\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import*\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import nltk\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpu = gpus[0]\n",
    "\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RyOqOiXOIBBu"
   },
   "outputs": [],
   "source": [
    "#Load  all these saved data\n",
    "\n",
    "with open('tokenizer_enc.pickle', 'rb') as file:\n",
    "    tokenizer_enc = pickle.load(file)\n",
    "    \n",
    "with open('tokenizer_dec.pickle', 'rb') as file:\n",
    "    tokenizer_dec = pickle.load(file)\n",
    "    \n",
    "with open('vocab_size_enc.pickle', 'rb') as file:\n",
    "    vocab_size_enc = pickle.load(file)\n",
    "\n",
    "with open('vocab_size_dec.pickle', 'rb') as file:\n",
    "    vocab_size_dec = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A5xVb8UoIBBu"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        #Initialize Embedding layer\n",
    "        self.enc_embed = Embedding(input_dim = inp_vocab_size, output_dim = embedding_size)\n",
    "        #Intialize Encoder LSTM layer\n",
    "        self.enc_lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
    "        \n",
    "    def call(self,input_sequence,states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        embedding = self.enc_embed(input_sequence)\n",
    "        output_state, enc_h, enc_c = self.enc_lstm(embedding, initial_state = states)\n",
    "        return output_state, enc_h, enc_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NH-HwuuzIBBv"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "        \n",
    "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "        \n",
    "        super(Attention, self).__init__()\n",
    "        self.scoring_function = scoring_function\n",
    "        \n",
    "        # Intialize variables needed for Dot score function here\n",
    "        if scoring_function == 'dot':\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "            pass\n",
    "        \n",
    "        # Intialize variables needed for General score function here\n",
    "        if scoring_function == 'general':\n",
    "            self.W = Dense(att_units)\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "            pass\n",
    "        \n",
    "        # Intialize variables needed for Concat score function here\n",
    "        if scoring_function == 'concat':\n",
    "            self.W1 = Dense(att_units)\n",
    "            self.W2 = Dense(att_units)\n",
    "            self.V = Dense(1)\n",
    "            pass\n",
    "        \n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "        \n",
    "        '''\n",
    "        Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "        Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "        '''\n",
    "    \n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        \n",
    "        if self.scoring_function == 'dot':\n",
    "            # Implement Dot score function here\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), encoder_output]), (0, 2,1))\n",
    "            pass\n",
    "            \n",
    "        elif self.scoring_function == 'general':\n",
    "            # Implement General score function here\n",
    "            mul = self.W(encoder_output)\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), mul]), (0, 2,1))\n",
    "            pass\n",
    "            \n",
    "        elif self.scoring_function == 'concat':\n",
    "            # Implement General score function here\n",
    "            inter = self.W1(decoder_hidden_state) + self.W2(encoder_output)\n",
    "            tan = tf.nn.tanh(inter)\n",
    "            score = self.V(tan)\n",
    "            pass\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis =1)\n",
    "        context_vector = attention_weights * encoder_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6ebKxz4xIBBw"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class One_Step_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        \n",
    "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        super().__init__()\n",
    "        self.tar_vocab_size = tar_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_dim = input_length\n",
    "        self.lstm_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.context_vector = 0\n",
    "        self.attention_weights = 0\n",
    "        self.dec_output = 0\n",
    "        self.decoder_state_h = 0\n",
    "        self.decoder_state_c = 0\n",
    "\n",
    "        self.Embedding_layer = Embedding(input_dim= self.tar_vocab_size, output_dim= self.embedding_dim,input_length= self.input_dim,\n",
    "                                      mask_zero = True, name = \"decoder_embedding_layer\")\n",
    "        self.LSTM_layer = LSTM(units = self.lstm_units, return_sequences= True,return_state= True, name = \"decoder_LSTM_layer\")\n",
    "\n",
    "        self.Attention_layer = Attention(self.score_fun, self.att_units)\n",
    "\n",
    "        self.Dense_layer = Dense(units = self.tar_vocab_size)\n",
    "        \n",
    "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "        '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "        '''\n",
    "        embedded_output = self.Embedding_layer(input_to_decoder)\n",
    "        \n",
    "        self.context_vector,self.attention_weights = self.Attention_layer(state_h,encoder_output)\n",
    "        self.context_vector = tf.expand_dims(self.context_vector, axis = 1)\n",
    "        \n",
    "        concanated_decoder_input = tf.concat([self.context_vector,embedded_output], axis = -1)\n",
    "        \n",
    "        self.dec_output, self.decoder_state_h, self.decoder_state_c = self.LSTM_layer(concanated_decoder_input,\n",
    "                                                                                      initial_state=[state_h, state_c])\n",
    "        \n",
    "        output = self.Dense_layer(self.dec_output)\n",
    "        output = tf.squeeze(output, axis =1)\n",
    "        \n",
    "        self.context_vector = tf.squeeze(self.context_vector)\n",
    "        \n",
    "        return output, self.decoder_state_h, self.decoder_state_c, self.attention_weights,self.context_vector\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.one_step_decoder = One_Step_Decoder(out_vocab_size, \n",
    "                                               embedding_dim, \n",
    "                                               input_length, \n",
    "                                               dec_units,\n",
    "                                               score_fun,\n",
    "                                               att_units)\n",
    "        \n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        \n",
    "    def call(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state):\n",
    "        \n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "        \n",
    "        all_outputs = tf.TensorArray(dtype = tf.float32, size= input_to_decoder.shape[1])\n",
    "        \n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.one_step_decoder(input_to_decoder[:, timestep:timestep+1], \n",
    "                                                                                             encoder_output, \n",
    "                                                                                             decoder_hidden_state,\n",
    "                                                                                             decoder_cell_state)\n",
    "            # Store the output in tensorarray\n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        # Return the tensor array\n",
    "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
    "        return all_outputs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lossfunction(targets,logits):\n",
    "    \n",
    "    # Custom loss function that will not consider the loss for padded zeros.\n",
    "    # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "    \n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    \n",
    "    loss_ = loss_object(targets, logits)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    \n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IKW-MnulIBBy"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "batch_size=32\n",
    "lstm_size=128\n",
    "max_dec = 50\n",
    "max_enc = 29\n",
    "embedding_dim = 100\n",
    "dense_units = 256\n",
    "att_units = 256\n",
    "latent_dim=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xUmxdBxqIBBy"
   },
   "outputs": [],
   "source": [
    "class pred_Encoder_decoder(tf.keras.Model): \n",
    "    \n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, max_ita, max_eng, score_fun, att_units):\n",
    "        #Intialize objects from encoder decoder\n",
    "        super(pred_Encoder_decoder, self).__init__()\n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, max_ita)\n",
    "        self.one_step_decoder = One_Step_Decoder(out_vocab_size, embedding_dim, max_eng, dec_units ,score_fun ,att_units)\n",
    "        self.batch_size = batch_size\n",
    "    def call(self, params):\n",
    "        enc_inp = params[0]\n",
    "        initial_state = self.encoder.initialize_states(1)\n",
    "        output_state, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
    "        pred = tf.expand_dims([tokenizer_dec.word_index['<sos>']], 0)\n",
    "        dec_h = enc_h\n",
    "        dec_c = enc_c\n",
    "        all_pred = []\n",
    "        all_attention = []\n",
    "        for t in range(50):  \n",
    "            pred, dec_h,dec_c, attention, _ = self.one_step_decoder(pred, output_state, dec_h, dec_c)\n",
    "            pred = tf.argmax(pred, axis = -1)\n",
    "            all_pred.append(pred)\n",
    "            pred = tf.expand_dims(pred, 0)\n",
    "            all_attention.append(attention)\n",
    "        return all_pred, all_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMSQXychIBBz",
    "outputId": "6bec4364-535a-4092-bbe7-a93b9046f9c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x224e6f4c1c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model = pred_Encoder_decoder(vocab_size_enc, \n",
    "                                  vocab_size_dec, \n",
    "                                  embedding_dim, \n",
    "                                  lstm_size,\n",
    "                                  lstm_size,\n",
    "                                  max_enc, \n",
    "                                  max_dec, \n",
    "                                  'concat',\n",
    "                                  att_units)\n",
    "\n",
    "pred_model.compile(optimizer = 'Adam', loss = custom_lossfunction)\n",
    "#Load the previously trained model\n",
    "pred_model.load_weights('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QcSpgwYbIBB0"
   },
   "outputs": [],
   "source": [
    "def decontractions(phrase):\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OdGpaXLDKhiD"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def final(X):\n",
    "    \n",
    "    seq = preprocess(X)\n",
    "    seq = '<sos> '+seq+' <eos>'\n",
    "    seq = tokenizer_enc.texts_to_sequences([seq])\n",
    "    seq = pad_sequences(seq, maxlen=max_enc, padding='post', dtype = np.int32)\n",
    "    pred, attention_weights = pred_model.predict(tf.expand_dims(seq, 0))\n",
    "    output = []\n",
    "    for i in pred:\n",
    "        word = tokenizer_dec.index_word[i[0]]\n",
    "        if word == '<eos>':\n",
    "            break\n",
    "        output.append(word)\n",
    "    return ' '.join(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axQ6Rfj6IBB0",
    "outputId": "8e1a2436-86e9-42e7-fefc-0552599b8d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  I am in the office\n",
      "predicted output :  on friday\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I am in the office'\n",
    "print('input : ', sentence)\n",
    "\n",
    "result = final(sentence)\n",
    "print('predicted output : ',result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YLMlUaQwIBB1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  Your support of\n",
      "predicted output :  the end of hurricane season buyer\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Your support of'\n",
    "print('input : ', sentence)\n",
    "\n",
    "result = final(sentence)\n",
    "print('predicted output : ',result)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_CS2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
